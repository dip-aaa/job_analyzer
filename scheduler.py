"""
scheduler.py â€” Master Pipeline Orchestrator
=============================================
This is the MAIN file you run to start the entire project.

What it does:
  1. Creates the database (first time only)
  2. Immediately runs the full pipeline (scrape â†’ clean)
  3. Keeps running, repeating the pipeline every 7 days

How to run:
  python scheduler.py

Keep this running in one terminal window.
In another terminal, run: streamlit run dashboard.py
"""

import schedule
import time
import sys
from datetime import datetime

# â”€â”€ Import the other modules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from database import setup_database

try:
    from merojob_scraper import scrape_jobs as scrape_mero
except ImportError as e:
    print(f"âŒ Could not import merojob_scraper: {e}")
    sys.exit(1)

try:
    from scrape_kumari import scrape_kumari_jobs as scrape_kumari
except ImportError as e:
    print(f"âŒ Could not import scrape_kumari: {e}")
    sys.exit(1)

try:
    from clean_data import clean_and_merge
except ImportError as e:
    print(f"âŒ Could not import clean_data: {e}")
    sys.exit(1)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  FULL PIPELINE FUNCTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def full_pipeline():
    """
    Runs all three stages in order:
      1. Scrape MeroJob
      2. Scrape KumariJob
      3. Clean and merge data into jobs_clean table
    """
    start = datetime.now()
    print("\n" + "â•" * 55)
    print(f"  ğŸš€ PIPELINE STARTED â€” {start.strftime('%Y-%m-%d %H:%M:%S')}")
    print("â•" * 55)

    # â”€â”€ Stage 1: Scrape MeroJob â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nâ–¶ [1/3] Scraping MeroJob...")
    try:
        mero_count = scrape_mero()
    except Exception as e:
        print(f"  âŒ MeroJob scraping failed: {e}")
        mero_count = 0

    # â”€â”€ Stage 2: Scrape KumariJob â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nâ–¶ [2/3] Scraping KumariJob...")
    try:
        kumari_count = scrape_kumari()
    except Exception as e:
        print(f"  âŒ KumariJob scraping failed: {e}")
        kumari_count = 0

    # â”€â”€ Stage 3: Clean and merge â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nâ–¶ [3/3] Cleaning and processing data...")
    try:
        df = clean_and_merge()
        clean_count = len(df) if df is not None else 0
    except Exception as e:
        print(f"  âŒ Cleaning failed: {e}")
        clean_count = 0

    # â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    end = datetime.now()
    duration = (end - start).seconds
    print("\n" + "â•" * 55)
    print(f"  âœ… PIPELINE COMPLETE â€” {end.strftime('%H:%M:%S')}")
    print(f"     Duration:      {duration} seconds")
    print(f"     MeroJob jobs:  {mero_count}")
    print(f"     KumariJob jobs:{kumari_count}")
    print(f"     Clean total:   {clean_count}")
    print(f"     Dashboard:     Refresh your browser to see updated data")
    print("â•" * 55 + "\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  STARTUP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("=" * 55)
print("  Nepal Job Market Dashboard â€” Pipeline Scheduler")
print("=" * 55)

# Step 1: Make sure database exists
print("\nğŸ—„  Setting up database...")
setup_database()

# Step 2: Run once immediately on startup
print("\nğŸ“¡ Running initial data collection (this takes a few minutes)...\n")
full_pipeline()

# Step 3: Schedule to run every 7 days
schedule.every(7).days.do(full_pipeline)

print("ğŸ“… Scheduler is active. Next run: in 7 days.")
print("\n" + "â”€" * 55)
print("  âœ… Now open a NEW terminal and run:")
print("     streamlit run dashboard.py")
print("â”€" * 55)
print("\n  Keeping scheduler running... (Ctrl+C to stop)\n")

# Keep the scheduler alive (checks every minute)
while True:
    try:
        schedule.run_pending()
        time.sleep(60)
    except KeyboardInterrupt:
        print("\n\nâ›” Scheduler stopped by user. Goodbye!")
        sys.exit(0)
